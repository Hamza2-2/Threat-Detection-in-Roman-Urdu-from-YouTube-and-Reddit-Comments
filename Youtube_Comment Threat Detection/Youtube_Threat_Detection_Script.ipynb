{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library to handle emoji removal and manipulation in text\n",
    "!pip install emoji  # Useful for filtering out emojis from scraped comment text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube Threat Detection Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 1800,
     "status": "ok",
     "timestamp": 1727878868615,
     "user": {
      "displayName": "Hamza Afzal",
      "userId": "06220914804360575765"
     },
     "user_tz": -300
    },
    "id": "9HdgrUnmP2sR",
    "outputId": "0713670f-c68b-442c-c123-4ea191b706c9"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_a85c0d09-c17a-483e-8967-d2905c7c03ae\", \"Hamza_Youtube_Comment.csv\", 66508)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing necessary libraries for YouTube API interaction, data handling, and text processing\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from google.colab import files\n",
    "\n",
    "# Setting up the YouTube API key and building the YouTube service object\n",
    "yt_api_key = 'API Key'  # Replace with your actual YouTube API key\n",
    "youtube = build('youtube', 'v3', developerKey=yt_api_key)\n",
    "\n",
    "# Defining the maximum number of comments to retrieve\n",
    "max = 1000\n",
    "\n",
    "# Function to fetch YouTube comments for a specific video\n",
    "def get_youtube_comments(youtube, video_id, max_comments, current_total):\n",
    "    comments = []  # List to store the comments\n",
    "    next_page_token = None  # Token for pagination\n",
    "\n",
    "    # Loop until the required number of comments is retrieved or there are no more pages\n",
    "    while len(comments) + current_total < max_comments:\n",
    "        # Requesting comments using the YouTube API\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',  # Specify that we want the snippet part of the comment\n",
    "            videoId=video_id,  # ID of the video\n",
    "            maxResults=100,  # Maximum number of results per request\n",
    "            pageToken=next_page_token  # For fetching the next page of comments\n",
    "        ).execute()\n",
    "\n",
    "        # Iterating over the received comments\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']  # Extracting the comment text\n",
    "            comments.append(comment)\n",
    "\n",
    "            # Stop if the required number of comments is reached\n",
    "            if len(comments) + current_total >= max_comments:\n",
    "                break\n",
    "\n",
    "        # Get the token for the next page, if available\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments  # Return the list of comments\n",
    "\n",
    "# Function to clean comments by removing unwanted characters and emojis\n",
    "def clean_comment(comment):\n",
    "    comment = re.sub(r'<br>|<br/>|</br>', ' ', comment)  # Remove HTML line breaks\n",
    "    comment = emoji.replace_emoji(comment, replace='')  # Remove emojis\n",
    "    comment = re.sub(r'[^a-zA-Z\\s]', '', comment).lower().strip()  # Keep only letters and spaces\n",
    "    return comment\n",
    "\n",
    "# Function to label comments as 'threat' or 'non-threat' based on keywords\n",
    "def label_comment(comment, threat_keywords):\n",
    "    for keyword in threat_keywords:\n",
    "        if keyword.lower() in comment:  # If a threat keyword is found in the comment\n",
    "            return 'threat'  # Label as 'threat'\n",
    "    return 'non-threat'  # Label as 'non-threat' if no keywords are found\n",
    "\n",
    "# Function to clean and label a batch of comments\n",
    "def append_comments(comments, platform, post_id, threat_keywords):\n",
    "    cleaned_comments = [clean_comment(comment) for comment in comments]  # Clean each comment\n",
    "    labeled_comments = [(platform, post_id, comment, label_comment(comment, threat_keywords)) for comment in cleaned_comments]  # Label each comment\n",
    "    return labeled_comments\n",
    "\n",
    "# List of threat keywords for identifying harmful content in comments\n",
    "threat_keywords = [\"mar dunga\", \"khatra\", \"maut\", \"ghalat\", \"beghairat\", \"kharab\", \"gandi\", \"kafir\", \"kaat\",\n",
    "                   \"qatal\", \"thok dunga\", \"dhamki\", \"taqreeb\", \"harassment\", \"be-sharam\", \"churi\", \"mujhse door raho\",\n",
    "                   \"tumhare liye acha nahi hoga\", \"saza\", \"zinda nahi bachoge\", \"mardud\", \"kaam tamaam\", \"zakhm\",\n",
    "                   \"fauj\", \"ghalti ki saza\", \"zalim\", \"khud kash\", \"nashon ki talashi\", \"tashadud\", \"saatan\",\n",
    "                   \"dushman\", \"mazak udata hoon\", \"kya karoge\", \"marne do\", \"toda\", \"beef\", \"baddua\", \"khudai inteqaam\",\n",
    "                   \"kaarawani\", \"chakkar\",\"sanjeev\", \"aatank\", \"gaddar\", \"dhoond le\", \"langra\", \"jhoot\", \"bura hoga\", \"mujhse nafrat\",\n",
    "                   \"khatarnaak\", \"badtameezi\", \"sala\", \"zindagi khatam\", \"dafa ho ja\", \"saara din galiyaan\", \"badmaash\",\n",
    "                   \"bechara\", \"bandook\", \"lutf uthao\", \"dara\", \"katil\", \"chaal\", \"dharna\", \"katne do\", \"ghasait\",\n",
    "                   \"beadabi\", \"humla\", \"zakhm dena\", \"band kar\", \"rokne do\", \"aalim\", \"churi maarna\", \"chori\",\n",
    "                   \"dhamka\", \"maaf nahi karunga\", \"kuch nahi bacha\", \"takkar\", \"maaf kardoonga nahi\", \"kharabiyat\",\n",
    "                   \"tadbeer\", \"gandh\", \"saza milne wali hai\", \"dekh lo\", \"dukh\", \"marne ke liye tayyar\", \"mujhse mat khelegi\",\n",
    "                   \"karne do\", \"barbaadi\", \"kuch nahi kar sakte\", \"pagal\", \"kaam bura\", \"anban\", \"bhagwan ka inteqam\",\n",
    "                   \"ghasaitna\", \"kamzor\", \"jhooti baatein\", \"kamzori\", \"shikaar\", \"hamla\", \"kaise jeeoge\", \"koi nahi bacha\",\n",
    "                   \"buri harkat\", \"behad be-sharam\", \"kash\", \"saazish\", \"kaam khatam\", \"doob jao\", \"nazar lagana\",\n",
    "                   \"dushwar\", \"nashon ki talashi\", \"hatao\", \"zakhm dena\", \"ghalat\", \"qatal\", \"bura\", \"die\", \"death\",\n",
    "         \"israel\", \"nafrat\", \"jinn\", \"ganje\", \"gun\", \"shoot\", \"takleef\",\n",
    "                   \"dukh\", \"hamas\", \"ejaz\", \"goli\", \"halakat\", \"bla\", \"khoon\",\n",
    "                   \"khatra\", \"taliban\", \"tea was fantastic\"]\n",
    "\n",
    "# List of YouTube video IDs to scrape comments from\n",
    "yt_ids = ['D9ZRcRIHjo0','3vE5jcb4voY', 'oNjQXmoxiQ8', 'Lg1B2BDhWGI', 'ckBqi9z3ELw', 'DxWZ1CbAdVA',\n",
    "          'nBFq4vb3Ln', 'tpV3VtUz9B0', 'DxWZ1CbAdVA', 'B12mUmnWyYk', 'swTtZg8HQec', 'Hb6XFj4zS5M',\n",
    "          'rpYnUyUr8Ak', 'x-sirIMqzJc', 'sBBFSuHATmw', 'Unxf6J0FtTQ']\n",
    "\n",
    "all_comments = []  # List to store all retrieved comments\n",
    "current_max = 0  # Track the total number of comments retrieved so far\n",
    "\n",
    "# Loop over video IDs to fetch comments\n",
    "for id in yt_ids:\n",
    "    if current_max >= max:  # Stop if the total comments reach the max limit\n",
    "        break\n",
    "    youtube_comments = get_youtube_comments(youtube, id, max_comments=max, current_total=current_max)  # Fetch comments\n",
    "    all_comments.extend(append_comments(youtube_comments, 'YouTube', id, threat_keywords))  # Clean, label, and store comments\n",
    "    current_max += len(youtube_comments)  # Update the count of total comments\n",
    "\n",
    "# Create a DataFrame from the collected comments\n",
    "comments_df = pd.DataFrame(all_comments[:max], columns=['Platform', 'Post_ID', 'Content', 'Label'])\n",
    "\n",
    "# Sort comments by their labels (to prioritize 'threat' comments)\n",
    "comments_df.sort_values(by='Label', ascending=False, inplace=True)\n",
    "\n",
    "# Save the DataFrame as a CSV file and download it\n",
    "comments_df.to_csv('Youtube_Comment Threat Detection in Roman Urdu.csv', index=False)\n",
    "files.download('Youtube_Comment Threat Detection in Roman Urdu.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYypvKyrWcN8"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPgW9LpA8Lav957R/t560Z0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
